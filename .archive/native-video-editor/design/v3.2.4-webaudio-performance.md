# WebAudio 성능 최적화 설계 일지 (v3.2.4)
> Phase 3.2 완료 - 오디오 성능 최적화

## 1. 문제 정의 & 요구사항

### 1.1 핵심 목표

**v3.2.4 - WebAudio Performance Optimization**:
- **버퍼 풀링**: AudioBuffer 재사용
- **노드 풀링**: AudioNode 재사용
- **메모리 관리**: GC 최소화
- **프로파일링**: 성능 측정

### 1.2 성능 목표

- 128 샘플 버퍼로 실시간 처리
- 메모리 사용 < 100MB
- GC 일시 정지 최소화

---

## 2. 패치별 상세 설계

### 3.2.4.1: 오디오 버퍼 풀

**파일**: `frontend/src/webaudio/AudioBufferPool.ts`

```typescript
export interface PooledBuffer {
  buffer: AudioBuffer;
  inUse: boolean;
  lastUsed: number;
}

export class AudioBufferPool {
  private context: AudioContext;
  private pools: Map<string, PooledBuffer[]> = new Map();
  private maxPoolSize: number;
  private cleanupInterval: number | null = null;

  constructor(context: AudioContext, maxPoolSize: number = 20) {
    this.context = context;
    this.maxPoolSize = maxPoolSize;
    
    // Periodic cleanup
    this.cleanupInterval = window.setInterval(() => {
      this.cleanup();
    }, 30000);
  }

  private getKey(channels: number, length: number, sampleRate: number): string {
    return `${channels}:${length}:${sampleRate}`;
  }

  acquire(channels: number, length: number, sampleRate?: number): AudioBuffer {
    const sr = sampleRate ?? this.context.sampleRate;
    const key = this.getKey(channels, length, sr);
    
    const pool = this.pools.get(key);
    if (pool) {
      const available = pool.find(pb => !pb.inUse);
      if (available) {
        available.inUse = true;
        available.lastUsed = Date.now();
        // Clear buffer data
        for (let i = 0; i < available.buffer.numberOfChannels; i++) {
          available.buffer.getChannelData(i).fill(0);
        }
        return available.buffer;
      }
    }

    // Create new buffer
    const buffer = this.context.createBuffer(channels, length, sr);
    this.addToPool(key, buffer, true);
    return buffer;
  }

  release(buffer: AudioBuffer): void {
    const key = this.getKey(
      buffer.numberOfChannels,
      buffer.length,
      buffer.sampleRate
    );
    const pool = this.pools.get(key);
    if (pool) {
      const pooled = pool.find(pb => pb.buffer === buffer);
      if (pooled) {
        pooled.inUse = false;
        pooled.lastUsed = Date.now();
      }
    }
  }

  private addToPool(key: string, buffer: AudioBuffer, inUse: boolean): void { ... }
  private cleanup(): void { /* Remove old unused buffers */ }

  getStats(): {
    poolCount: number;
    totalBuffers: number;
    inUse: number;
    available: number;
  } {
    // Calculate pool statistics
  }

  clear(): void { this.pools.clear(); }
  dispose(): void {
    if (this.cleanupInterval !== null) {
      clearInterval(this.cleanupInterval);
    }
    this.clear();
  }
}
```

---

### 3.2.4.2: 노드 재사용

**파일**: `frontend/src/webaudio/AudioNodePool.ts`

```typescript
export type NodeFactory<T extends AudioNode> = (context: AudioContext) => T;
export type NodeResetter<T extends AudioNode> = (node: T) => void;

export interface PooledNode<T extends AudioNode> {
  node: T;
  inUse: boolean;
  lastUsed: number;
}

export class AudioNodePool<T extends AudioNode> {
  private context: AudioContext;
  private pool: PooledNode<T>[] = [];
  private factory: NodeFactory<T>;
  private resetter: NodeResetter<T>;
  private maxSize: number;

  constructor(
    context: AudioContext,
    factory: NodeFactory<T>,
    resetter: NodeResetter<T>,
    maxSize: number = 20
  ) {
    this.context = context;
    this.factory = factory;
    this.resetter = resetter;
    this.maxSize = maxSize;
  }

  acquire(): T {
    // Find available node and reset it
    const available = this.pool.find(pn => !pn.inUse);
    if (available) {
      available.inUse = true;
      available.lastUsed = Date.now();
      this.resetter(available.node);
      return available.node;
    }

    // Create new node
    const node = this.factory(this.context);
    if (this.pool.length < this.maxSize) {
      this.pool.push({ node, inUse: true, lastUsed: Date.now() });
    }
    return node;
  }

  release(node: T): void {
    const pooled = this.pool.find(pn => pn.node === node);
    if (pooled) {
      pooled.inUse = false;
      pooled.lastUsed = Date.now();
      try { node.disconnect(); } catch { /* Already disconnected */ }
    }
  }

  getStats(): { total: number; inUse: number; available: number } { ... }
  clear(): void { ... }
}

/**
 * 다양한 노드 타입을 위한 통합 풀 관리자
 */
export class AudioNodePoolManager {
  private gainPool: AudioNodePool<GainNode>;
  private filterPool: AudioNodePool<BiquadFilterNode>;
  private delayPool: AudioNodePool<DelayNode>;
  private pannerPool: AudioNodePool<StereoPannerNode>;

  constructor(context: AudioContext) {
    this.gainPool = new AudioNodePool(
      context,
      ctx => ctx.createGain(),
      node => { node.gain.value = 1; }
    );
    this.filterPool = new AudioNodePool(
      context,
      ctx => ctx.createBiquadFilter(),
      node => {
        node.type = 'lowpass';
        node.frequency.value = 350;
        node.Q.value = 1;
        node.gain.value = 0;
      }
    );
    this.delayPool = new AudioNodePool(
      context,
      ctx => ctx.createDelay(5),
      node => { node.delayTime.value = 0; }
    );
    this.pannerPool = new AudioNodePool(
      context,
      ctx => ctx.createStereoPanner(),
      node => { node.pan.value = 0; }
    );
  }

  acquireGain(): GainNode { return this.gainPool.acquire(); }
  releaseGain(node: GainNode): void { this.gainPool.release(node); }
  acquireFilter(): BiquadFilterNode { return this.filterPool.acquire(); }
  releaseFilter(node: BiquadFilterNode): void { this.filterPool.release(node); }
  acquireDelay(): DelayNode { return this.delayPool.acquire(); }
  releaseDelay(node: DelayNode): void { this.delayPool.release(node); }
  acquirePanner(): StereoPannerNode { return this.pannerPool.acquire(); }
  releasePanner(node: StereoPannerNode): void { this.pannerPool.release(node); }

  getStats(): Record<string, { total: number; inUse: number; available: number }> {
    return {
      gain: this.gainPool.getStats(),
      filter: this.filterPool.getStats(),
      delay: this.delayPool.getStats(),
      panner: this.pannerPool.getStats(),
    };
  }

  clear(): void { ... }
}
```

---

### 3.2.4.3: 메모리 관리

**파일**: `frontend/src/webaudio/AudioMemoryManager.ts`

```typescript
export interface AudioMemoryStats {
  estimatedBufferMemory: number;
  activeNodes: number;
  cachedBuffers: number;
  peakMemory: number;
}

export class AudioMemoryManager {
  private trackedBuffers: Map<string, { buffer: AudioBuffer; size: number }> = new Map();
  private activeNodeCount: number = 0;
  private peakMemory: number = 0;
  private memoryWarningThreshold: number;
  private onMemoryWarning?: (usage: number) => void;

  constructor(
    memoryWarningThresholdMB: number = 256,
    onMemoryWarning?: (usage: number) => void
  ) {
    this.memoryWarningThreshold = memoryWarningThresholdMB * 1024 * 1024;
    this.onMemoryWarning = onMemoryWarning;
  }

  trackBuffer(id: string, buffer: AudioBuffer): void {
    const size = this.calculateBufferSize(buffer);
    this.trackedBuffers.set(id, { buffer, size });
    this.checkMemoryUsage();
  }

  untrackBuffer(id: string): void {
    this.trackedBuffers.delete(id);
  }

  trackNode(): void { this.activeNodeCount++; }
  untrackNode(): void { this.activeNodeCount = Math.max(0, this.activeNodeCount - 1); }

  private calculateBufferSize(buffer: AudioBuffer): number {
    return buffer.length * buffer.numberOfChannels * 4; // Float32 = 4 bytes
  }

  private checkMemoryUsage(): void {
    const usage = this.getEstimatedMemory();
    if (usage > this.peakMemory) {
      this.peakMemory = usage;
    }
    if (usage > this.memoryWarningThreshold && this.onMemoryWarning) {
      this.onMemoryWarning(usage);
    }
  }

  getEstimatedMemory(): number {
    let total = 0;
    for (const { size } of this.trackedBuffers.values()) {
      total += size;
    }
    return total;
  }

  getStats(): AudioMemoryStats {
    return {
      estimatedBufferMemory: this.getEstimatedMemory(),
      activeNodes: this.activeNodeCount,
      cachedBuffers: this.trackedBuffers.size,
      peakMemory: this.peakMemory,
    };
  }

  cleanup(keepIds: Set<string>): number {
    let freed = 0;
    for (const [id, { size }] of this.trackedBuffers.entries()) {
      if (!keepIds.has(id)) {
        this.trackedBuffers.delete(id);
        freed += size;
      }
    }
    return freed;
  }

  evictToSize(targetSizeBytes: number): string[] {
    // LRU 기반 메모리 해제
  }

  formatBytes(bytes: number): string {
    if (bytes < 1024) return `${bytes} B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(2)} KB`;
    return `${(bytes / (1024 * 1024)).toFixed(2)} MB`;
  }

  logStats(): void {
    const stats = this.getStats();
    console.group('Audio Memory Stats');
    console.log(`Buffer Memory: ${this.formatBytes(stats.estimatedBufferMemory)}`);
    console.log(`Peak Memory: ${this.formatBytes(stats.peakMemory)}`);
    console.log(`Cached Buffers: ${stats.cachedBuffers}`);
    console.log(`Active Nodes: ${stats.activeNodes}`);
    console.groupEnd();
  }

  clear(): void { ... }
}
```

---

### 3.2.4.4: WebAudio 프로파일링

**파일**: `frontend/src/webaudio/AudioPerformanceProfiler.ts`

```typescript
export interface AudioPerformanceMetrics {
  contextTime: number;
  baseLatency: number;
  outputLatency: number;
  bufferUnderruns: number;
  processingLoad: number;
  averageCallbackTime: number;
}

export interface CallbackTiming {
  timestamp: number;
  duration: number;
}

export class AudioPerformanceProfiler {
  private context: AudioContext;
  private callbackTimings: CallbackTiming[] = [];
  private maxTimings: number = 1000;
  private bufferUnderruns: number = 0;
  private isMonitoring: boolean = false;
  private monitorNode: ScriptProcessorNode | null = null;

  constructor(context: AudioContext) {
    this.context = context;
  }

  startMonitoring(): void {
    if (this.isMonitoring) return;
    this.isMonitoring = true;

    // Use ScriptProcessorNode for timing measurement
    this.monitorNode = this.context.createScriptProcessor(256, 1, 1);
    
    let lastTime = 0;
    this.monitorNode.onaudioprocess = (e) => {
      const now = performance.now();
      if (lastTime > 0) {
        const expectedInterval = (e.inputBuffer.length / this.context.sampleRate) * 1000;
        const actualInterval = now - lastTime;
        
        if (actualInterval > expectedInterval * 1.5) {
          this.bufferUnderruns++;
        }
        this.recordTiming(actualInterval);
      }
      lastTime = now;
    };

    // Connect (silent monitoring)
    const silentGain = this.context.createGain();
    silentGain.gain.value = 0;
    this.monitorNode.connect(silentGain);
    silentGain.connect(this.context.destination);
  }

  stopMonitoring(): void {
    if (!this.isMonitoring) return;
    this.isMonitoring = false;
    if (this.monitorNode) {
      this.monitorNode.disconnect();
      this.monitorNode = null;
    }
  }

  private recordTiming(duration: number): void { ... }

  getMetrics(): AudioPerformanceMetrics {
    const avgCallbackTime = this.calculateAverageCallbackTime();
    const processingLoad = this.estimateProcessingLoad();
    const ctx = this.context as AudioContext & { outputLatency?: number };

    return {
      contextTime: this.context.currentTime,
      baseLatency: this.context.baseLatency,
      outputLatency: ctx.outputLatency ?? 0,
      bufferUnderruns: this.bufferUnderruns,
      processingLoad,
      averageCallbackTime: avgCallbackTime,
    };
  }

  private calculateAverageCallbackTime(): number { ... }
  private estimateProcessingLoad(): number { ... }

  getLatencyInfo(): { input: number; output: number; total: number } {
    const base = this.context.baseLatency;
    const ctx = this.context as AudioContext & { outputLatency?: number };
    const output = ctx.outputLatency ?? 0;
    return { input: base, output, total: base + output };
  }

  getTimingHistory(): CallbackTiming[] { return [...this.callbackTimings]; }
  resetStats(): void { this.callbackTimings = []; this.bufferUnderruns = 0; }

  logMetrics(): void {
    const metrics = this.getMetrics();
    const latency = this.getLatencyInfo();

    console.group('Audio Performance Metrics');
    console.log(`Context Time: ${metrics.contextTime.toFixed(3)}s`);
    console.log(`Base Latency: ${(latency.input * 1000).toFixed(2)}ms`);
    console.log(`Output Latency: ${(latency.output * 1000).toFixed(2)}ms`);
    console.log(`Total Latency: ${(latency.total * 1000).toFixed(2)}ms`);
    console.log(`Buffer Underruns: ${metrics.bufferUnderruns}`);
    console.log(`Avg Callback Time: ${metrics.averageCallbackTime.toFixed(2)}ms`);
    console.log(`Processing Load: ${(metrics.processingLoad * 100).toFixed(1)}%`);
    console.groupEnd();
  }

  dispose(): void {
    this.stopMonitoring();
    this.callbackTimings = [];
  }
}
```

---

## 3. 완료 기준

- [ ] 버퍼 풀링으로 할당 감소
- [ ] 노드 풀링으로 재사용
- [ ] GC 일시 정지 최소화
- [ ] 프로파일링 메트릭 확인 가능
- [ ] 메모리 사용 < 100MB

---

## 4. Phase 3.2 완료

Phase 3 Extended (WebGL + WebAudio) 구현 완료.

다음 단계:
- 통합 테스트
- 성능 벤치마크
- 문서 업데이트
