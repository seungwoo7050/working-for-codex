# 오디오 시각화 설계 일지 (v3.2.3)
> Phase 3.2 - 오디오 데이터 시각화

## 1. 문제 정의 & 요구사항

### 1.1 핵심 목표

**v3.2.3 - Audio Visualization**:
- **웨이브폼 렌더링**: 시간 도메인 데이터 표시
- **스펙트로그램**: 주파수 도메인 2D 표시
- **실시간 시각화**: 애니메이션 프레임 동기화
- **WebGL 가속**: GPU 기반 렌더링

---

## 2. 패치별 상세 설계

### 3.2.3.1: 웨이브폼 렌더링

**파일**: `frontend/src/webaudio/WaveformRenderer.ts`

```typescript
export interface WaveformStyle {
  lineColor?: string;
  lineWidth?: number;
  fillColor?: string;
  backgroundColor?: string;
  centerLine?: boolean;
  centerLineColor?: string;
}

export class WaveformRenderer {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;
  private style: Required<WaveformStyle>;

  constructor(canvas: HTMLCanvasElement, style: WaveformStyle = {}) {
    this.canvas = canvas;
    const ctx = canvas.getContext('2d');
    if (!ctx) {
      throw new Error('Failed to get 2D context');
    }
    this.ctx = ctx;

    this.style = {
      lineColor: style.lineColor ?? '#00ff00',
      lineWidth: style.lineWidth ?? 2,
      fillColor: style.fillColor ?? 'rgba(0, 255, 0, 0.3)',
      backgroundColor: style.backgroundColor ?? '#000000',
      centerLine: style.centerLine ?? true,
      centerLineColor: style.centerLineColor ?? 'rgba(255, 255, 255, 0.3)',
    };
  }

  setStyle(style: Partial<WaveformStyle>): void {
    Object.assign(this.style, style);
  }

  /**
   * 실시간 오디오 데이터 렌더링
   */
  renderRealtime(timeDomainData: Uint8Array): void {
    // Clear and draw center line
    // Draw waveform line
  }

  /**
   * AudioBuffer 전체 파형 렌더링
   */
  renderBuffer(buffer: AudioBuffer, channel?: number): void {
    // Calculate samples per pixel
    // Draw waveform as min/max bars
  }

  /**
   * 축소된 파형 데이터 생성 (정적 메서드)
   */
  static generateWaveformData(
    buffer: AudioBuffer,
    channel: number,
    pointCount: number
  ): { min: Float32Array; max: Float32Array } {
    // Generate min/max data for efficient rendering
  }

  /**
   * 축소된 데이터로 빠른 렌더링
   */
  renderWaveformData(
    data: { min: Float32Array; max: Float32Array },
    startIndex?: number,
    endIndex?: number
  ): void {
    // Render pre-computed waveform data
  }

  clear(): void {
    this.ctx.fillStyle = this.style.backgroundColor;
    this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
  }
}
```

---

### 3.2.3.2: 스펙트로그램

**파일**: `frontend/src/webaudio/SpectrogramRenderer.ts`

```typescript
export interface SpectrogramStyle {
  colorMap?: 'viridis' | 'magma' | 'plasma' | 'grayscale' | 'rainbow';
  backgroundColor?: string;
  minDecibels?: number;
  maxDecibels?: number;
}

export class SpectrogramRenderer {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;
  private style: Required<SpectrogramStyle>;
  private imageData: ImageData;

  constructor(canvas: HTMLCanvasElement, style: SpectrogramStyle = {}) {
    this.canvas = canvas;
    const ctx = canvas.getContext('2d');
    if (!ctx) {
      throw new Error('Failed to get 2D context');
    }
    this.ctx = ctx;

    this.style = {
      colorMap: style.colorMap ?? 'viridis',
      backgroundColor: style.backgroundColor ?? '#000000',
      minDecibels: style.minDecibels ?? -100,
      maxDecibels: style.maxDecibels ?? -30,
    };

    this.imageData = ctx.createImageData(canvas.width, canvas.height);
    this.clear();
  }

  setStyle(style: Partial<SpectrogramStyle>): void {
    Object.assign(this.style, style);
  }

  /**
   * 주파수 데이터 한 컬럼 추가 (스크롤링)
   */
  addColumn(frequencyData: Uint8Array): void {
    // Shift existing data left
    // Add new column at the right
    // Put image data
  }

  /**
   * 전체 버퍼 스펙트로그램 렌더링
   */
  renderBuffer(
    buffer: AudioBuffer,
    fftSize?: number,
    hopSize?: number
  ): void {
    // Full offline analysis requires OfflineAudioContext with AnalyserNode
  }

  private getColor(value: number): { r: number; g: number; b: number } {
    switch (this.style.colorMap) {
      case 'grayscale':
        return this.grayscale(value);
      case 'rainbow':
        return this.rainbow(value);
      case 'magma':
        return this.magma(value);
      case 'plasma':
        return this.plasma(value);
      case 'viridis':
      default:
        return this.viridis(value);
    }
  }

  private grayscale(t: number): { r: number; g: number; b: number } { ... }
  private rainbow(t: number): { r: number; g: number; b: number } { ... }
  private viridis(t: number): { r: number; g: number; b: number } { ... }
  private magma(t: number): { r: number; g: number; b: number } { ... }
  private plasma(t: number): { r: number; g: number; b: number } { ... }

  clear(): void {
    const { width, height } = this.canvas;
    this.ctx.fillStyle = this.style.backgroundColor;
    this.ctx.fillRect(0, 0, width, height);
    this.imageData = this.ctx.createImageData(width, height);
  }

  resize(): void {
    this.imageData = this.ctx.createImageData(this.canvas.width, this.canvas.height);
  }
}
```

---

### 3.2.3.3: 실시간 시각화

**파일**: `frontend/src/webaudio/RealtimeVisualizer.ts`

```typescript
import { FFTAnalyzer } from './FFTAnalyzer';

export type VisualizationType = 'bars' | 'line' | 'circle' | 'particles';

export interface VisualizerStyle {
  type?: VisualizationType;
  barColor?: string;
  barGradient?: string[];
  barWidth?: number;
  barGap?: number;
  lineColor?: string;
  lineWidth?: number;
  circleRadius?: number;
  particleCount?: number;
  backgroundColor?: string;
  mirror?: boolean;
}

export class RealtimeVisualizer {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;
  private analyzer: FFTAnalyzer;
  private style: Required<VisualizerStyle>;
  private animationId: number | null = null;
  private isRunning: boolean = false;

  constructor(
    canvas: HTMLCanvasElement,
    analyzer: FFTAnalyzer,
    style: VisualizerStyle = {}
  ) {
    this.canvas = canvas;
    this.ctx = canvas.getContext('2d')!;
    this.analyzer = analyzer;

    this.style = {
      type: style.type ?? 'bars',
      barColor: style.barColor ?? '#00ff00',
      barGradient: style.barGradient ?? [],
      barWidth: style.barWidth ?? 4,
      barGap: style.barGap ?? 2,
      lineColor: style.lineColor ?? '#00ff00',
      lineWidth: style.lineWidth ?? 2,
      circleRadius: style.circleRadius ?? 100,
      particleCount: style.particleCount ?? 100,
      backgroundColor: style.backgroundColor ?? '#000000',
      mirror: style.mirror ?? false,
    };
  }

  setStyle(style: Partial<VisualizerStyle>): void {
    Object.assign(this.style, style);
  }

  start(): void {
    if (this.isRunning) return;
    this.isRunning = true;
    this.render();
  }

  stop(): void {
    this.isRunning = false;
    if (this.animationId !== null) {
      cancelAnimationFrame(this.animationId);
      this.animationId = null;
    }
  }

  private render = (): void => {
    if (!this.isRunning) return;

    this.clear();

    switch (this.style.type) {
      case 'bars':
        this.renderBars();
        break;
      case 'line':
        this.renderLine();
        break;
      case 'circle':
        this.renderCircle();
        break;
      case 'particles':
        this.renderParticles();
        break;
    }

    this.animationId = requestAnimationFrame(this.render);
  };

  private renderBars(): void { /* Frequency bar visualization */ }
  private renderLine(): void { /* Frequency line visualization */ }
  private renderCircle(): void { /* Circular visualization */ }
  private renderParticles(): void { /* Particle visualization */ }

  dispose(): void {
    this.stop();
  }
}
```

---

### 3.2.3.4: WebGL 오디오 시각화

**파일**: `frontend/src/webaudio/WebGLAudioVisualizer.ts`

```typescript
export interface WebGLVisualizerOptions {
  particleCount?: number;
  particleSize?: number;
  colorPalette?: number[][];
}

export class WebGLAudioVisualizer {
  private canvas: HTMLCanvasElement;
  private gl: WebGL2RenderingContext;
  private program: WebGLProgram | null = null;
  private vao: WebGLVertexArrayObject | null = null;
  private frequencyTexture: WebGLTexture | null = null;
  private animationId: number | null = null;
  private isRunning: boolean = false;
  private frequencyData: Uint8Array;
  private options: Required<WebGLVisualizerOptions>;

  constructor(
    canvas: HTMLCanvasElement,
    frequencyBinCount: number,
    options: WebGLVisualizerOptions = {}
  ) {
    this.canvas = canvas;
    const gl = canvas.getContext('webgl2');
    if (!gl) {
      throw new Error('WebGL2 not supported');
    }
    this.gl = gl;

    this.options = {
      particleCount: options.particleCount ?? 5000,
      particleSize: options.particleSize ?? 3,
      colorPalette: options.colorPalette ?? [
        [0, 0.5, 1],
        [0, 1, 0.5],
        [1, 0.5, 0],
      ],
    };

    this.frequencyData = new Uint8Array(frequencyBinCount);
    this.initGL();
  }

  private initGL(): void {
    // Compile vertex/fragment shaders
    // Create program, VAO, VBO
    // Initialize frequency texture
    // Enable blending
  }

  private compileShader(type: number, source: string): WebGLShader | null {
    // Compile and return shader
  }

  updateFrequencyData(data: Uint8Array): void {
    this.frequencyData.set(data);
    // Update texture with frequency data
  }

  start(): void {
    if (this.isRunning) return;
    this.isRunning = true;
    this.render();
  }

  stop(): void {
    this.isRunning = false;
    if (this.animationId !== null) {
      cancelAnimationFrame(this.animationId);
      this.animationId = null;
    }
  }

  private render = (): void => {
    if (!this.isRunning || !this.program) return;

    const gl = this.gl;
    // Set viewport, clear, use program
    // Set uniforms (time, resolution, frequency texture)
    // Draw particles
    this.animationId = requestAnimationFrame(this.render);
  };

  dispose(): void {
    this.stop();
    
    const gl = this.gl;
    if (this.program) gl.deleteProgram(this.program);
    if (this.vao) gl.deleteVertexArray(this.vao);
    if (this.frequencyTexture) gl.deleteTexture(this.frequencyTexture);
  }
}
```

---

## 3. 완료 기준

- [ ] 웨이브폼 렌더링 동작
- [ ] 스펙트로그램 실시간 업데이트
- [ ] 실시간 시각화 60 FPS
- [ ] WebGL 가속 시각화

---

## 4. 다음 단계

→ v3.2.4: WebAudio 성능 최적화
