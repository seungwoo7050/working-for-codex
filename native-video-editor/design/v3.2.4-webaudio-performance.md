# WebAudio 성능 최적화 설계 일지 (v3.2.4)
> Phase 3.2 완료 - 오디오 성능 최적화

## 1. 문제 정의 & 요구사항

### 1.1 핵심 목표

**v3.2.4 - WebAudio Performance Optimization**:
- **버퍼 풀링**: AudioBuffer 재사용
- **노드 풀링**: AudioNode 재사용
- **메모리 관리**: GC 최소화
- **프로파일링**: 성능 측정

### 1.2 성능 목표

- 128 샘플 버퍼로 실시간 처리
- 메모리 사용 < 100MB
- GC 일시 정지 최소화

---

## 2. 패치별 상세 설계

### 3.2.4.1: 오디오 버퍼 풀

**파일**: `frontend/src/audio/AudioBufferPool.ts`

```typescript
interface PoolConfig {
  maxSize: number;
  preAllocate: number;
}

class AudioBufferPool {
  private context: AudioContext;
  private pools: Map<string, AudioBuffer[]> = new Map();
  private config: PoolConfig;
  
  constructor(context: AudioContext, config?: Partial<PoolConfig>) {
    this.context = context;
    this.config = {
      maxSize: config?.maxSize ?? 50,
      preAllocate: config?.preAllocate ?? 10,
    };
  }
  
  private getKey(channels: number, length: number): string {
    return `${channels}_${length}`;
  }
  
  preAllocate(channels: number, length: number): void {
    const key = this.getKey(channels, length);
    if (!this.pools.has(key)) {
      this.pools.set(key, []);
    }
    
    const pool = this.pools.get(key)!;
    for (let i = 0; i < this.config.preAllocate; i++) {
      pool.push(this.context.createBuffer(channels, length, this.context.sampleRate));
    }
  }
  
  acquire(channels: number, length: number): AudioBuffer {
    const key = this.getKey(channels, length);
    const pool = this.pools.get(key);
    
    if (pool && pool.length > 0) {
      const buffer = pool.pop()!;
      this.clearBuffer(buffer);
      return buffer;
    }
    
    return this.context.createBuffer(channels, length, this.context.sampleRate);
  }
  
  release(buffer: AudioBuffer): void {
    const key = this.getKey(buffer.numberOfChannels, buffer.length);
    
    if (!this.pools.has(key)) {
      this.pools.set(key, []);
    }
    
    const pool = this.pools.get(key)!;
    if (pool.length < this.config.maxSize) {
      pool.push(buffer);
    }
    // If pool is full, let buffer be GC'd
  }
  
  private clearBuffer(buffer: AudioBuffer): void {
    for (let c = 0; c < buffer.numberOfChannels; c++) {
      const channel = buffer.getChannelData(c);
      channel.fill(0);
    }
  }
  
  getStats(): { pooledBuffers: number; memoryBytes: number } {
    let count = 0;
    let bytes = 0;
    
    this.pools.forEach(pool => {
      count += pool.length;
      pool.forEach(buffer => {
        bytes += buffer.length * buffer.numberOfChannels * 4;
      });
    });
    
    return { pooledBuffers: count, memoryBytes: bytes };
  }
}
```

---

### 3.2.4.2: 노드 재사용

**파일**: `frontend/src/audio/NodePool.ts`

```typescript
type NodeFactory<T extends AudioNode> = () => T;

class NodePool<T extends AudioNode> {
  private context: AudioContext;
  private factory: NodeFactory<T>;
  private available: T[] = [];
  private inUse: Set<T> = new Set();
  private maxSize: number;
  
  constructor(context: AudioContext, factory: NodeFactory<T>, maxSize = 20) {
    this.context = context;
    this.factory = factory;
    this.maxSize = maxSize;
  }
  
  acquire(): T {
    let node: T;
    
    if (this.available.length > 0) {
      node = this.available.pop()!;
    } else {
      node = this.factory();
    }
    
    this.inUse.add(node);
    return node;
  }
  
  release(node: T): void {
    if (!this.inUse.has(node)) return;
    
    this.inUse.delete(node);
    node.disconnect();
    
    if (this.available.length < this.maxSize) {
      this.available.push(node);
    }
    // If pool is full, node will be GC'd
  }
  
  releaseAll(): void {
    this.inUse.forEach(node => {
      node.disconnect();
      if (this.available.length < this.maxSize) {
        this.available.push(node);
      }
    });
    this.inUse.clear();
  }
  
  getStats(): { available: number; inUse: number } {
    return {
      available: this.available.length,
      inUse: this.inUse.size,
    };
  }
}

// Factory methods for common nodes
class AudioNodePools {
  private context: AudioContext;
  gainPool: NodePool<GainNode>;
  filterPool: NodePool<BiquadFilterNode>;
  delayPool: NodePool<DelayNode>;
  
  constructor(context: AudioContext) {
    this.context = context;
    this.gainPool = new NodePool(context, () => context.createGain());
    this.filterPool = new NodePool(context, () => context.createBiquadFilter());
    this.delayPool = new NodePool(context, () => context.createDelay(5));
  }
}
```

---

### 3.2.4.3: 메모리 관리

**파일**: `frontend/src/audio/AudioMemoryManager.ts`

```typescript
interface MemoryStats {
  audioBuffers: number;
  audioNodes: number;
  estimatedBytes: number;
  gcPressure: 'low' | 'medium' | 'high';
}

class AudioMemoryManager {
  private context: AudioContext;
  private bufferPool: AudioBufferPool;
  private nodePools: AudioNodePools;
  private allocationCount = 0;
  private lastGcCheck = 0;
  
  constructor(context: AudioContext) {
    this.context = context;
    this.bufferPool = new AudioBufferPool(context);
    this.nodePools = new AudioNodePools(context);
    
    // Pre-allocate common buffer sizes
    this.bufferPool.preAllocate(2, 2048);  // Stereo, ~46ms at 44.1kHz
    this.bufferPool.preAllocate(2, 4096);  // Stereo, ~93ms at 44.1kHz
  }
  
  acquireBuffer(channels: number, length: number): AudioBuffer {
    this.allocationCount++;
    return this.bufferPool.acquire(channels, length);
  }
  
  releaseBuffer(buffer: AudioBuffer): void {
    this.bufferPool.release(buffer);
  }
  
  getStats(): MemoryStats {
    const bufferStats = this.bufferPool.getStats();
    const gainStats = this.nodePools.gainPool.getStats();
    const filterStats = this.nodePools.filterPool.getStats();
    
    const totalNodes = gainStats.available + gainStats.inUse +
                       filterStats.available + filterStats.inUse;
    
    return {
      audioBuffers: bufferStats.pooledBuffers,
      audioNodes: totalNodes,
      estimatedBytes: bufferStats.memoryBytes,
      gcPressure: this.estimateGcPressure(),
    };
  }
  
  private estimateGcPressure(): 'low' | 'medium' | 'high' {
    // Simple heuristic based on allocation rate
    const now = performance.now();
    const elapsed = now - this.lastGcCheck;
    
    if (elapsed > 1000) {
      const allocationsPerSecond = this.allocationCount / (elapsed / 1000);
      this.allocationCount = 0;
      this.lastGcCheck = now;
      
      if (allocationsPerSecond > 100) return 'high';
      if (allocationsPerSecond > 50) return 'medium';
    }
    
    return 'low';
  }
}
```

---

### 3.2.4.4: WebAudio 프로파일링

**파일**: `frontend/src/audio/AudioProfiler.ts`

```typescript
interface AudioMetrics {
  contextTime: number;
  renderQuantum: number;
  processingLoad: number;
  bufferUnderruns: number;
  latency: number;
}

class AudioProfiler {
  private context: AudioContext;
  private startTime: number;
  private underrunCount = 0;
  private lastRenderTime = 0;
  private renderDeltas: number[] = [];
  
  constructor(context: AudioContext) {
    this.context = context;
    this.startTime = performance.now();
    this.setupMonitoring();
  }
  
  private setupMonitoring(): void {
    // Monitor for buffer underruns using a ScriptProcessor
    // (In production, use AudioWorklet for better accuracy)
    const monitor = this.context.createScriptProcessor(256, 1, 1);
    monitor.onaudioprocess = () => {
      const now = performance.now();
      const delta = now - this.lastRenderTime;
      
      // Expected: ~5.8ms for 256 samples at 44.1kHz
      if (delta > 10) {
        this.underrunCount++;
      }
      
      this.renderDeltas.push(delta);
      if (this.renderDeltas.length > 100) {
        this.renderDeltas.shift();
      }
      
      this.lastRenderTime = now;
    };
    
    // Connect to keep alive but don't output sound
    const silence = this.context.createGain();
    silence.gain.value = 0;
    monitor.connect(silence);
    silence.connect(this.context.destination);
  }
  
  getMetrics(): AudioMetrics {
    const avgDelta = this.renderDeltas.length > 0
      ? this.renderDeltas.reduce((a, b) => a + b, 0) / this.renderDeltas.length
      : 0;
    
    return {
      contextTime: this.context.currentTime,
      renderQuantum: 128, // Fixed in WebAudio
      processingLoad: avgDelta / 5.8, // Ratio to expected time
      bufferUnderruns: this.underrunCount,
      latency: this.context.baseLatency + ((this.context as any).outputLatency ?? 0),
    };
  }
  
  reset(): void {
    this.underrunCount = 0;
    this.renderDeltas = [];
  }
  
  log(): void {
    const metrics = this.getMetrics();
    console.log('[AudioProfiler]', {
      time: metrics.contextTime.toFixed(2) + 's',
      load: (metrics.processingLoad * 100).toFixed(1) + '%',
      underruns: metrics.bufferUnderruns,
      latency: (metrics.latency * 1000).toFixed(1) + 'ms',
    });
  }
}
```

---

## 3. 완료 기준

- [ ] 버퍼 풀링으로 할당 감소
- [ ] 노드 풀링으로 재사용
- [ ] GC 일시 정지 최소화
- [ ] 프로파일링 메트릭 확인 가능
- [ ] 메모리 사용 < 100MB

---

## 4. Phase 3.2 완료

Phase 3 Extended (WebGL + WebAudio) 구현 완료.

다음 단계:
- 통합 테스트
- 성능 벤치마크
- 문서 업데이트
