```markdown
# CLAUDE.md - cpp-pvp-server v3.2 운영 성숙도

> AI 코딩 에이전트를 위한 프로젝트 컨텍스트 가이드 (시니어 레벨)

## 프로젝트 개요

### 선행 조건
- v3.0.0 멀티 리전 아키텍처 완료
- v3.1.0 대규모 성능 최적화 완료

### 현재 상태 (v3.1.0)
- 10만+ 동시 접속 처리 가능
- 락-프리 데이터 구조 적용
- io_uring 기반 고성능 네트워킹

### 목표 상태 (v3.2.0)
- **프로덕션 레벨** 운영 성숙도
- 카오스 엔지니어링
- 자동 스케일링
- SLO/SLI 모니터링

## 버전 로드맵 (v3.2 세부화)

| 버전 | 기간 | 설명 |
|------|------|------|
| v3.2.0 | 2주 | 카오스 엔지니어링 |
| v3.2.1 | 2주 | 자동 스케일링 |
| v3.2.2 | 2주 | SLO/SLI 대시보드 |
| v3.2.3 | 2주 | 인프라 자동화 |

---

## v3.2.0: 카오스 엔지니어링

### 작업 내용
| 순서 | 작업 | 핵심 파일 |
|------|------|----------|
| 3.2.0.1 | ChaosEngine 구현 | `ChaosEngine.cpp` |
| 3.2.0.2 | 장애 주입 유형 정의 | `ChaosEngine.hpp` |
| 3.2.0.3 | 실험 프레임워크 | `ChaosExperiment.cpp` |
| 3.2.0.4 | 페일오버 테스트 | `tests/chaos/` |

### 구현 세부 사항
- 다양한 장애 유형 주입 (네트워크, 서버, 리소스)
- 실험 프레임워크로 안정성 검증
- 자동 복구 시간 측정

#### 3.2.0.1 ChaosEngine
```cpp
// ChaosEngine.hpp
class ChaosEngine {
public:
    // 장애 주입 유형
    enum class FaultType {
        NETWORK_LATENCY,    // 네트워크 지연 추가
        NETWORK_PARTITION,  // 네트워크 분할
        SERVER_CRASH,       // 서버 크래시
        CPU_STRESS,         // CPU 과부하
        MEMORY_PRESSURE,    // 메모리 압박
        DISK_FULL,          // 디스크 풀
    };

    struct FaultConfig {
        FaultType type;
        std::string target;         // 대상 서버/서비스
        Duration duration;          // 지속 시간
        float intensity = 1.0f;     // 강도 (0.0 ~ 1.0)
        std::string description;
    };

    // 장애 주입
    void injectFault(const FaultConfig& config);
    
    // 장애 해제
    void clearFault(const std::string& faultId);
    
    // 실험 실행
    struct ExperimentResult {
        bool passed;
        Duration recoveryTime;
        std::vector<std::string> observations;
        std::vector<std::string> recommendations;
    };
    
    ExperimentResult runExperiment(
        const std::string& hypothesis,
        const std::vector<FaultConfig>& faults,
        std::function<bool()> steadyStateCheck
    );
};

// 사용 예시: 리전 장애 복구 테스트
void testRegionFailover() {
    ChaosEngine chaos;
    
    auto result = chaos.runExperiment(
        "한국 리전 장애 시 일본 리전으로 자동 페일오버",
        {
            {FaultType::NETWORK_PARTITION, "region-kr", 5min, 1.0f, "한국 리전 격리"}
        },
        []() {
            // 정상 상태 확인: 모든 플레이어가 게임 가능
            return getAllPlayersCanPlay();
        }
    );
    
    EXPECT_TRUE(result.passed);
    EXPECT_LT(result.recoveryTime, 30s);  // 30초 이내 복구
}
```

---

## v3.2.1: 자동 스케일링

### 작업 내용
| 순서 | 작업 | 핵심 파일 |
|------|------|----------|
| 3.2.1.1 | AutoScaler 구현 | `AutoScaler.cpp` |
| 3.2.1.2 | 스케일링 정책 | `ScalingPolicy.cpp` |
| 3.2.1.3 | 예측 기반 스케일링 | `PredictiveScaler.cpp` |
| 3.2.1.4 | Kubernetes HPA 연동 | `k8s/hpa.yaml` |

### 커밋 포인트
```bash
git commit -m "feat(scale): implement AutoScaler with threshold policies"
git commit -m "feat(scale): add configurable scaling policies"
git commit -m "feat(scale): add predictive scaling with time series model"
git commit -m "infra(k8s): add Kubernetes HPA configuration"
git tag -a v3.2.1 -m "v3.2.1: Auto Scaling"
```

### 상세 구현 가이드

#### 3.2.1.1 AutoScaler
```cpp
// AutoScaler.hpp
class AutoScaler {
public:
    struct ScalingPolicy {
        std::string metricName;     // "cpu_usage", "player_count", "queue_depth"
        float scaleUpThreshold;
        float scaleDownThreshold;
        Duration cooldown;
        int minInstances;
        int maxInstances;
        int scaleUpStep;
        int scaleDownStep;
    };

    void setPolicy(const ScalingPolicy& policy) {
        policy_ = policy;
    }
    
    void evaluate() {
        float currentValue = getMetricValue(policy_.metricName);
        
        if (currentValue > policy_.scaleUpThreshold && canScale()) {
            scaleUp(policy_.scaleUpStep);
            lastScaleTime_ = now();
        } else if (currentValue < policy_.scaleDownThreshold && canScale()) {
            scaleDown(policy_.scaleDownStep);
            lastScaleTime_ = now();
        }
    }

private:
    bool canScale() {
        return (now() - lastScaleTime_) > policy_.cooldown;
    }
    
    void scaleUp(int count);
    void scaleDown(int count);
    
    ScalingPolicy policy_;
    TimePoint lastScaleTime_;
};

// 예측 기반 스케일링
class PredictiveScaler : public AutoScaler {
public:
    void evaluate() override {
        // 과거 데이터 기반 예측
        float predictedLoad = model_.predict(
            getHistoricalData(24h),
            forecastHorizon(1h)
        );
        
        // 예측 부하에 맞춰 미리 스케일
        int requiredInstances = calculateRequiredInstances(predictedLoad);
        scaleTo(requiredInstances);
    }

private:
    TimeSeriesModel model_;  // ARIMA, Prophet 등
};
```

---

## v3.2.2: SLO/SLI 대시보드

### 작업 내용
| 순서 | 작업 | 핵심 파일 |
|------|------|----------|
| 3.2.2.1 | SLOMonitor 구현 | `SLOMonitor.cpp` |
| 3.2.2.2 | SLI 정의 | `SLOMonitor.hpp` |
| 3.2.2.3 | 에러 버짓 관리 | `SLOMonitor.cpp` |
| 3.2.2.4 | Grafana 대시보드 | `monitoring/grafana/` |

### 커밋 포인트
```bash
git commit -m "feat(slo): implement SLOMonitor with SLI definitions"
git commit -m "feat(slo): add error budget tracking"
git commit -m "feat(slo): add alerting on budget consumption"
git commit -m "infra(grafana): add SLO dashboard"
git tag -a v3.2.2 -m "v3.2.2: SLO/SLI Dashboard"
```

### 상세 구현 가이드

#### 3.2.2.1 SLOMonitor
```cpp
// SLOMonitor.hpp
class SLOMonitor {
public:
    struct SLI {
        std::string name;
        std::string query;  // Prometheus 쿼리
        float target;       // 목표값
        Duration window;    // 측정 윈도우
    };

    struct SLO {
        std::string name;
        std::vector<SLI> indicators;
        float targetAvailability;  // 예: 99.9%
        Duration budget;           // 에러 버짓 기간
    };

    // SLO 등록
    void registerSLO(const SLO& slo);
    
    // 현재 상태 조회
    struct SLOStatus {
        std::string sloName;
        float currentAvailability;
        Duration remainingBudget;
        bool isHealthy;
        std::vector<std::string> burningIndicators;
    };
    
    SLOStatus getStatus(const std::string& sloName);
    
    // 알림 설정
    void setAlert(
        const std::string& sloName,
        float budgetThreshold,      // 남은 버짓 비율
        std::function<void(const SLOStatus&)> alertHandler
    );
};

// 사용 예시
void setupGameServerSLOs() {
    SLOMonitor monitor;
    
    monitor.registerSLO({
        .name = "game-server-availability",
        .indicators = {
            {"latency_p99", "histogram_quantile(0.99, rate(request_latency_bucket[5m]))", 0.020, 5min},
            {"error_rate", "rate(errors_total[5m]) / rate(requests_total[5m])", 0.001, 5min},
            {"matchmaking_time", "histogram_quantile(0.95, rate(matchmaking_latency_bucket[5m]))", 30.0, 5min},
        },
        .targetAvailability = 0.999,  // 99.9%
        .budget = 30days
    });
    
    monitor.setAlert("game-server-availability", 0.5, [](const auto& status) {
        // 에러 버짓 50% 소진 시 알림
        sendSlackAlert("SLO budget burning: " + status.sloName);
    });
}
```

---

## v3.2.3: 인프라 자동화

### 작업 내용
| 순서 | 작업 | 핵심 파일 |
|------|------|----------|
| 3.2.3.1 | Terraform 모듈 | `infrastructure/terraform/` |
| 3.2.3.2 | Kubernetes 매니페스트 | `infrastructure/kubernetes/` |
| 3.2.3.3 | CI/CD 파이프라인 | `.github/workflows/` |
| 3.2.3.4 | 배포 문서화 | `docs/DEPLOYMENT.md` |

### 커밋 포인트
```bash
git commit -m "infra(terraform): add multi-region terraform modules"
git commit -m "infra(k8s): add Kubernetes manifests with overlays"
git commit -m "ci: add GitHub Actions for CI/CD"
git commit -m "docs: add deployment documentation"
git tag -a v3.2.3 -m "v3.2.3: Infrastructure Automation Complete"
```

## 파일 구조

```
cpp-pvp-server/
├── server/
│   ├── src/
│   │   ├── operations/
│   │   │   ├── ChaosEngine.cpp
│   │   │   ├── ChaosEngine.hpp
│   │   │   ├── AutoScaler.cpp
│   │   │   ├── AutoScaler.hpp
│   │   │   ├── PredictiveScaler.cpp
│   │   │   ├── SLOMonitor.cpp
│   │   │   └── SLOMonitor.hpp
│   │   └── ...
│   └── tests/
│       ├── chaos/
│       │   └── RegionFailoverTest.cpp
│       ├── load/
│       │   └── LoadTest.cpp
│       └── failover/
│           └── FailoverTest.cpp
├── infrastructure/
│   ├── terraform/
│   │   ├── modules/
│   │   │   ├── region/
│   │   │   └── global/
│   │   └── environments/
│   │       ├── production/
│   │       └── staging/
│   └── kubernetes/
│       ├── base/
│       └── overlays/
└── monitoring/
    └── grafana/
        └── dashboards/
```

## 운영 요구사항

| 메트릭 | 목표값 |
|--------|--------|
| 가용성 | 99.9% (연간 다운타임 < 8.76시간) |
| RTO (Recovery Time Objective) | 5분 |
| RPO (Recovery Point Objective) | 1분 |
| 페일오버 시간 | < 30초 |

## 학습 자료

### 카오스 엔지니어링
- [Chaos Engineering (O'Reilly)](https://www.oreilly.com/library/view/chaos-engineering/9781492043850/)
- [Netflix Chaos Monkey](https://netflix.github.io/chaosmonkey/)

### SRE
- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)
- [SLO 기반 알림](https://sre.google/workbook/alerting-on-slos/)
```
