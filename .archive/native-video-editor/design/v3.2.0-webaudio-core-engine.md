# WebAudio 코어 엔진 설계 일지 (v3.2.0)
> Phase 3.2 시작 - WebAudio 기반 오디오 편집

## 1. 문제 정의 & 요구사항

### 1.1 핵심 목표

**v3.2.0 - WebAudio Core Engine**:
- **AudioContext 초기화**: 브라우저 오디오 시스템 설정
- **오디오 파일 로딩**: fetch + decodeAudioData
- **버퍼 관리**: AudioBuffer 풀링 및 재사용
- **디버깅**: 오디오 상태 추적

### 1.2 성능 요구사항

- 128 샘플 버퍼로 실시간 처리
- FFT 분석 < 10ms
- 메모리 사용 < 100MB

### 1.3 브라우저 지원

- Chrome 14+
- Firefox 25+
- Safari 6+
- Edge 12+

---

## 2. 아키텍처 설계

### 2.1 디렉토리 구조

```
frontend/src/webaudio/
├── AudioContextManager.ts # AudioContext 관리
├── AudioLoader.ts         # 파일 로딩
├── AudioBufferManager.ts  # 버퍼 관리
├── AudioDebug.ts          # 디버깅 유틸리티
└── index.ts               # 모듈 익스포트
```

### 2.2 클래스 다이어그램

```
┌─────────────────────────────────────────────────────┐
│               AudioContextManager                    │
├─────────────────────────────────────────────────────┤
│ - context: AudioContext | null                      │
│ - isResumed: boolean                                │
│ - stateChangeListeners: Set                         │
├─────────────────────────────────────────────────────┤
│ + getContext(): Promise<AudioContext>               │
│ + resume(): Promise<void>                           │
│ + suspend(): Promise<void>                          │
│ + close(): Promise<void>                            │
│ + getState(): AudioContextState | null              │
│ + getSampleRate(): number                           │
└─────────────────────────────────────────────────────┘
         │
         ├──────────────────┬──────────────────┐
         ▼                  ▼                  ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│   AudioLoader   │ │AudioBufferMgr   │ │   AudioDebug    │
├─────────────────┤ ├─────────────────┤ ├─────────────────┤
│ + load()        │ │ + add()         │ │ + enable()      │
│ + loadFromFile()│ │ + get()         │ │ + log/warn/err  │
│ + getCached()   │ │ + createEmpty() │ │ + getInfo()     │
└─────────────────┘ └─────────────────┘ └─────────────────┘
```

---

## 3. 패치별 상세 설계

### 3.2.0.1: AudioContext 초기화

**파일**: `frontend/src/webaudio/AudioContextManager.ts`

```typescript
interface AudioContextOptions {
  sampleRate?: number;
  latencyHint?: 'interactive' | 'balanced' | 'playback';
}

class AudioContextManager {
  private context: AudioContext | null = null;
  private isResumed: boolean = false;
  private stateChangeListeners: Set<(state: AudioContextState) => void> = new Set();
  
  constructor(private options: AudioContextOptions = {}) {}
  
  async getContext(): Promise<AudioContext> {
    if (!this.context) {
      this.context = new AudioContext({
        sampleRate: this.options.sampleRate,
        latencyHint: this.options.latencyHint ?? 'interactive',
      });
      
      this.context.onstatechange = () => {
        this.notifyStateChange();
      };
    }
    
    if (this.context.state === 'suspended' && !this.isResumed) {
      await this.resume();
    }
    
    return this.context;
  }
  
  async resume(): Promise<void> {
    if (this.context && this.context.state === 'suspended') {
      await this.context.resume();
      this.isResumed = true;
    }
  }
  
  async suspend(): Promise<void> {
    if (this.context && this.context.state === 'running') {
      await this.context.suspend();
    }
  }
  
  async close(): Promise<void> {
    if (this.context) {
      await this.context.close();
      this.context = null;
      this.isResumed = false;
    }
  }
  
  getState(): AudioContextState | null {
    return this.context?.state ?? null;
  }
  
  getSampleRate(): number {
    return this.context?.sampleRate ?? this.options.sampleRate ?? 44100;
  }
  
  getCurrentTime(): number {
    return this.context?.currentTime ?? 0;
  }
}
```

**핵심 포인트**:
1. 자동 resume 설정 (브라우저 정책 대응)
2. 마스터 게인 노드로 전체 볼륨 제어
3. 리소스 정리 (dispose)

---

### 3.2.0.2: 오디오 파일 로딩

**파일**: `frontend/src/webaudio/AudioLoader.ts`

```typescript
interface LoadProgress {
  loaded: number;
  total: number;
  percent: number;
}

class AudioLoader {
  private context: AudioContext;
  private cache: Map<string, AudioBuffer> = new Map();
  
  constructor(context: AudioContext) {
    this.context = context;
  }
  
  async load(
    url: string,
    onProgress?: (progress: LoadProgress) => void
  ): Promise<AudioBuffer> {
    // Check cache
    const cached = this.cache.get(url);
    if (cached) return cached;
    
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`Failed to load audio: ${response.statusText}`);
    }
    
    const contentLength = response.headers.get('content-length');
    const total = contentLength ? parseInt(contentLength, 10) : 0;
    
    if (onProgress && total > 0 && response.body) {
      // Stream with progress
      const reader = response.body.getReader();
      const chunks: Uint8Array[] = [];
      let loaded = 0;
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        chunks.push(value);
        loaded += value.length;
        onProgress({ loaded, total, percent: (loaded / total) * 100 });
      }
      
      const arrayBuffer = this.concatArrayBuffers(chunks);
      const audioBuffer = await this.context.decodeAudioData(arrayBuffer);
      this.cache.set(url, audioBuffer);
      return audioBuffer;
    } else {
      const arrayBuffer = await response.arrayBuffer();
      const audioBuffer = await this.context.decodeAudioData(arrayBuffer);
      this.cache.set(url, audioBuffer);
      return audioBuffer;
    }
  }
  
  async loadFromFile(file: File): Promise<AudioBuffer> {
    const arrayBuffer = await file.arrayBuffer();
    return this.context.decodeAudioData(arrayBuffer);
  }
  
  getCached(url: string): AudioBuffer | undefined {
    return this.cache.get(url);
  }
  
  clearCache(): void {
    this.cache.clear();
  }
}
```

**핵심 포인트**:
1. URL 및 File 객체 지원
2. 캐싱으로 중복 로딩 방지
3. decodeAudioData로 디코딩

---

### 3.2.0.3: 오디오 버퍼 관리

**파일**: `frontend/src/webaudio/AudioBufferManager.ts`

```typescript
interface BufferInfo {
  id: string;
  buffer: AudioBuffer;
  duration: number;
  sampleRate: number;
  channels: number;
  lastUsed: number;
}

class AudioBufferManager {
  private context: AudioContext;
  private buffers: Map<string, BufferInfo> = new Map();
  private memoryLimit: number;
  
  constructor(context: AudioContext, memoryLimitMB: number = 128) {
    this.context = context;
    this.memoryLimit = memoryLimitMB * 1024 * 1024;
  }
  
  add(id: string, buffer: AudioBuffer): void {
    this.buffers.set(id, {
      id,
      buffer,
      duration: buffer.duration,
      sampleRate: buffer.sampleRate,
      channels: buffer.numberOfChannels,
      lastUsed: Date.now(),
    });
    this.checkMemoryLimit();
  }
  
  get(id: string): AudioBuffer | null {
    const info = this.buffers.get(id);
    if (info) {
      info.lastUsed = Date.now();
      return info.buffer;
    }
    return null;
  }
  
  has(id: string): boolean {
    return this.buffers.has(id);
  }
  
  remove(id: string): boolean {
    return this.buffers.delete(id);
  }
  
  createEmpty(
    channels: number,
    length: number,
    sampleRate?: number
  ): AudioBuffer {
    return this.context.createBuffer(
      channels,
      length,
      sampleRate ?? this.context.sampleRate
    );
  }
  
  clone(buffer: AudioBuffer): AudioBuffer {
    const newBuffer = this.createEmpty(
      buffer.numberOfChannels,
      buffer.length,
      buffer.sampleRate
    );
    for (let i = 0; i < buffer.numberOfChannels; i++) {
      const channelData = new Float32Array(buffer.length);
      buffer.copyFromChannel(channelData, i);
      newBuffer.copyToChannel(channelData, i);
    }
    return newBuffer;
  }
}
```

---

### 3.2.0.4: WebAudio 디버깅

**파일**: `frontend/src/webaudio/AudioDebug.ts`

```typescript
interface AudioDebugInfo {
  contextState: AudioContextState | null;
  sampleRate: number;
  currentTime: number;
  baseLatency: number;
  outputLatency: number;
  activeNodes: number;
}

class AudioDebug {
  private context: AudioContext;
  private nodeCount: number = 0;
  private logs: Array<{ timestamp: number; message: string; level: string }> = [];
  private maxLogs: number = 100;
  private isEnabled: boolean = true;
  
  constructor(context: AudioContext) {
    this.context = context;
  }
  
  enable(): void { this.isEnabled = true; }
  disable(): void { this.isEnabled = false; }
  
  log(message: string): void {
    if (!this.isEnabled) return;
    this.addLog('info', message);
    console.log(`[AudioDebug] ${message}`);
  }
  
  warn(message: string): void {
    if (!this.isEnabled) return;
    this.addLog('warn', message);
    console.warn(`[AudioDebug] ${message}`);
  }
  
  error(message: string): void {
    if (!this.isEnabled) return;
    this.addLog('error', message);
    console.error(`[AudioDebug] ${message}`);
  }
  
  private addLog(level: string, message: string): void {
    this.logs.push({ timestamp: Date.now(), level, message });
    if (this.logs.length > this.maxLogs) this.logs.shift();
  }
  
  trackNode(node: AudioNode): void {
    this.nodeCount++;
    this.log(`Node created: ${node.constructor.name} (total: ${this.nodeCount})`);
  }
  
  untrackNode(node: AudioNode): void {
    this.nodeCount--;
    this.log(`Node disposed: ${node.constructor.name} (total: ${this.nodeCount})`);
  }
  
  getInfo(): AudioDebugInfo {
    return {
      contextState: this.context.state,
      sampleRate: this.context.sampleRate,
      currentTime: this.context.currentTime,
      baseLatency: this.context.baseLatency,
      outputLatency: (this.context as any).outputLatency ?? 0,
      activeNodes: this.nodeCount,
    };
  }
  
  getLogs(): Array<{ timestamp: number; message: string; level: string }> {
    return [...this.logs];
  }
}
```

---

## 4. 완료 기준

- [ ] AudioContext 초기화 및 resume
- [ ] 오디오 파일 로딩 및 디코딩
- [ ] 버퍼 재사용 시스템 동작
- [ ] 디버그 모드에서 상태 로깅

---

## 5. 다음 단계

→ v3.2.1: 오디오 노드 시스템
