# CLAUDE.md - cpp-pvp-server v3.0 대규모 트래픽 처리

> AI 코딩 에이전트를 위한 프로젝트 컨텍스트 가이드 (시니어 레벨)

## 프로젝트 개요

### 선행 조건
- v2.1.0 안티 치트 시스템 완료

### 현재 상태 (v2.1.0)
- 분산 서버 및 안티 치트 구축
- 1만 동시 접속 처리 가능

### 목표 상태 (v3.0.0)
- 10만+ 동시 접속 처리
- 멀티 리전 글로벌 서비스
- 프로덕션 레벨 운영 성숙도

## 버전 로드맵 (v3.0 세부화)

| 버전 | 기간 | 설명 |
|------|------|------|
| v3.0.0 | 2개월 | 멀티 리전 아키텍처 |
| v3.0.1 | 2개월 | 대규모 성능 최적화 |
| v3.0.2 | 2개월 | 운영 성숙도 및 자동화 |

---

## v3.0.0: 멀티 리전 아키텍처

### 작업 내용
| 순서 | 작업 | 핵심 요구사항 |
|------|------|---------------|
| 3.0.0.1 | RegionCluster 구현 | 리전별 독립 클러스터 구성 |
| 3.0.0.2 | GlobalMatchmaking 구현 | 글로벌 매칭메이킹 및 리전 선택 |
| 3.0.0.3 | CrossRegionSync 구현 | 크로스 리전 데이터 동기화 |
| 3.0.0.4 | 글로벌 코디네이션 레이어 | 글로벌 서비스 통합 |

### 구현 세부 사항
- 지역별 독립 클러스터 운영
- 플레이어 지연 기반 최적 리전 선택
- CRDT 기반 최종 일관성 동기화

---

## v3.0.1: 대규모 성능 최적화

### 작업 내용
| 순서 | 작업 | 핵심 요구사항 |
|------|------|---------------|
| 3.0.1.1 | LockFreeQueue 구현 | 락-프리 데이터 구조 |
| 3.0.1.2 | NUMAAllocator 구현 | NUMA-aware 메모리 할당 |
| 3.0.1.3 | IoUringNetwork 구현 | io_uring 기반 고성능 네트워킹 |
| 3.0.1.4 | 성능 최적화 통합 | 모든 컴포넌트에 적용 |

### 구현 세부 사항
- 락-프리 큐로 동시성 개선
- NUMA 노드별 메모리 할당 최적화
- io_uring으로 네트워크 I/O 성능 향상

---

## v3.0.2: 운영 성숙도 및 자동화

### 작업 내용
| 순서 | 작업 | 핵심 요구사항 |
|------|------|---------------|
| 3.0.2.1 | ChaosEngine 구현 | 카오스 엔지니어링 장애 주입 |
| 3.0.2.2 | AutoScaler 구현 | 자동 스케일링 및 예측 스케일링 |
| 3.0.2.3 | SLOMonitor 구현 | SLO/SLI 모니터링 및 알림 |
| 3.0.2.4 | 운영 자동화 통합 | CI/CD 및 인프라 자동화 |

### 구현 세부 사항
- 장애 주입을 통한 복원력 테스트
- 메트릭 기반 자동 스케일링
- 서비스 레벨 목표 모니터링 및 알림

#### 1.1 글로벌 인프라 설계
```
목표: 지역별 독립 클러스터 + 글로벌 조정

┌────────────────────────────────────────────────────────────────┐
│                      Global Architecture                        │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐             │
│  │   Korea     │  │   Japan     │  │  Singapore  │             │
│  │   Region    │  │   Region    │  │   Region    │             │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘             │
│         │                │                │                     │
│         ▼                ▼                ▼                     │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │              Global Coordination Layer                   │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐      │   │
│  │  │ Global      │  │ Cross-Region│  │ Global      │      │   │
│  │  │ Matchmaking │  │ Data Sync   │  │ Leaderboard │      │   │
│  │  └─────────────┘  └─────────────┘  └─────────────┘      │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└────────────────────────────────────────────────────────────────┘
```

#### 1.2 리전 클러스터 구성
```cpp
// RegionCluster.hpp
struct RegionConfig {
    std::string regionId;           // "kr", "jp", "sg"
    std::string displayName;        // "Korea", "Japan", "Singapore"
    std::vector<std::string> zones; // ["kr-a", "kr-b", "kr-c"]
    
    // 리전 내 서버 설정
    int minGameServers = 3;
    int maxGameServers = 100;
    int playersPerServer = 1000;
    
    // 네트워크 설정
    std::string vpcCidr;
    std::map<std::string, int> latencyToOtherRegions; // ms
};

class RegionCluster {
public:
    explicit RegionCluster(const RegionConfig& config);
    
    // 리전 내 서버 관리
    void scaleUp(int count);
    void scaleDown(int count);
    std::vector<GameServerInfo> getAvailableServers() const;
    
    // 리전 상태
    RegionHealth getHealth() const;
    int getCurrentPlayerCount() const;
    float getAverageLatency() const;
    
    // 크로스 리전 통신
    void syncToGlobal(const GlobalSyncData& data);
    GlobalSyncData receiveFromGlobal();

private:
    RegionConfig config_;
    std::vector<std::unique_ptr<GameServer>> servers_;
    std::unique_ptr<RegionCoordinator> coordinator_;
};
```

#### 1.3 글로벌 매칭메이킹
```cpp
// GlobalMatchmaking.hpp
class GlobalMatchmaking {
public:
    struct MatchRequest {
        PlayerId playerId;
        int eloRating;
        std::string preferredRegion;  // 선호 리전
        int maxLatency = 100;         // 최대 허용 지연 (ms)
        GameMode gameMode;
    };

    struct MatchResult {
        MatchId matchId;
        std::string assignedRegion;
        std::string gameServerAddress;
        int expectedLatency;
        std::vector<PlayerId> players;
    };

    // 글로벌 매칭
    std::future<MatchResult> findMatch(const MatchRequest& request);

private:
    // 리전 선택 알고리즘
    std::string selectOptimalRegion(
        const std::vector<PlayerId>& players,
        int maxLatency
    );

    // 각 리전의 플레이어 큐
    std::map<std::string, MatchmakingQueue> regionalQueues_;
    
    // 크로스 리전 매칭 (선택적)
    bool allowCrossRegion_ = true;
};

// 리전 선택 알고리즘
std::string GlobalMatchmaking::selectOptimalRegion(
    const std::vector<PlayerId>& players,
    int maxLatency
) {
    // 1. 각 플레이어의 리전별 지연 시간 수집
    std::map<std::string, std::vector<int>> latencies;
    for (const auto& player : players) {
        auto playerLatencies = getPlayerLatencies(player);
        for (const auto& [region, latency] : playerLatencies) {
            latencies[region].push_back(latency);
        }
    }
    
    // 2. 모든 플레이어가 maxLatency 이내인 리전 찾기
    std::string bestRegion;
    int bestMaxLatency = INT_MAX;
    
    for (const auto& [region, lats] : latencies) {
        int maxLat = *std::max_element(lats.begin(), lats.end());
        if (maxLat <= maxLatency && maxLat < bestMaxLatency) {
            bestMaxLatency = maxLat;
            bestRegion = region;
        }
    }
    
    return bestRegion;
}
```

#### 1.4 크로스 리전 데이터 동기화
```cpp
// CrossRegionSync.hpp
class CrossRegionSync {
public:
    // 동기화 대상 데이터 유형
    enum class SyncType {
        PLAYER_PROFILE,     // 플레이어 프로필 (ELO, 통계)
        GLOBAL_LEADERBOARD, // 글로벌 랭킹
        BAN_LIST,           // 밴 목록 (즉시 동기화)
        FRIEND_STATUS,      // 친구 온라인 상태
    };

    // 동기화 전략
    enum class SyncStrategy {
        EVENTUAL,           // 최종 일관성 (1-5초 지연 허용)
        STRONG,             // 강한 일관성 (즉시)
    };

    void sync(SyncType type, const SyncData& data, SyncStrategy strategy);
    
    // Conflict Resolution
    SyncData resolveConflict(
        const SyncData& local,
        const SyncData& remote,
        SyncType type
    );

private:
    // CRDTs (Conflict-free Replicated Data Types) 사용
    template<typename T>
    class LWWRegister {  // Last-Writer-Wins Register
        T value_;
        Timestamp timestamp_;
    public:
        void update(const T& value, Timestamp ts) {
            if (ts > timestamp_) {
                value_ = value;
                timestamp_ = ts;
            }
        }
    };
};
```

### Phase 2: 대규모 성능 최적화 (Month 3-4)

#### 2.1 락-프리 데이터 구조
```cpp
// LockFreeQueue.hpp
template<typename T>
class LockFreeQueue {
public:
    void enqueue(T item) {
        Node* newNode = new Node{std::move(item), nullptr};
        Node* oldTail = tail_.load(std::memory_order_relaxed);
        
        while (true) {
            Node* next = oldTail->next.load(std::memory_order_acquire);
            
            if (next == nullptr) {
                if (oldTail->next.compare_exchange_weak(
                    next, newNode,
                    std::memory_order_release,
                    std::memory_order_relaxed
                )) {
                    tail_.compare_exchange_strong(
                        oldTail, newNode,
                        std::memory_order_release,
                        std::memory_order_relaxed
                    );
                    return;
                }
            } else {
                tail_.compare_exchange_weak(
                    oldTail, next,
                    std::memory_order_release,
                    std::memory_order_relaxed
                );
            }
            oldTail = tail_.load(std::memory_order_relaxed);
        }
    }

    std::optional<T> dequeue() {
        // ... Michael-Scott queue dequeue 구현
    }

private:
    struct Node {
        T data;
        std::atomic<Node*> next;
    };
    
    std::atomic<Node*> head_;
    std::atomic<Node*> tail_;
};
```

#### 2.2 NUMA-aware 메모리 할당
```cpp
// NUMAAllocator.hpp
class NUMAAllocator {
public:
    // 현재 스레드의 NUMA 노드에서 메모리 할당
    void* allocateLocal(size_t size) {
        int node = getCurrentNUMANode();
        return numa_alloc_onnode(size, node);
    }
    
    // 특정 NUMA 노드에서 할당
    void* allocateOnNode(size_t size, int node) {
        return numa_alloc_onnode(size, node);
    }
    
    // 모든 노드에 인터리브 할당 (공유 데이터용)
    void* allocateInterleaved(size_t size) {
        return numa_alloc_interleaved(size);
    }

    // 스레드를 특정 NUMA 노드에 고정
    void bindThreadToNode(int node) {
        cpu_set_t cpuset;
        CPU_ZERO(&cpuset);
        
        // 해당 노드의 모든 CPU 추가
        for (int cpu : getNodeCPUs(node)) {
            CPU_SET(cpu, &cpuset);
        }
        
        pthread_setaffinity_np(pthread_self(), sizeof(cpuset), &cpuset);
    }

private:
    int getCurrentNUMANode() {
        return numa_node_of_cpu(sched_getcpu());
    }
};

// 사용 예시: 게임 서버에서 플레이어 데이터를 NUMA 로컬로 관리
class NUMAGameServer {
public:
    void assignPlayerToNode(PlayerId player) {
        int node = player.hash() % numa_num_configured_nodes();
        playerNodes_[player] = node;
        
        // 플레이어 데이터를 해당 노드에 할당
        auto* data = (PlayerData*)allocator_.allocateOnNode(
            sizeof(PlayerData), node
        );
        playerData_[player] = data;
    }
};
```

#### 2.3 io_uring 기반 네트워킹
```cpp
// IoUringNetwork.hpp
class IoUringNetwork {
public:
    IoUringNetwork(int queueDepth = 4096) {
        io_uring_queue_init(queueDepth, &ring_, 0);
    }
    
    ~IoUringNetwork() {
        io_uring_queue_exit(&ring_);
    }

    // 비동기 수신 등록
    void prepareRecv(int fd, void* buffer, size_t len, void* userData) {
        io_uring_sqe* sqe = io_uring_get_sqe(&ring_);
        io_uring_prep_recv(sqe, fd, buffer, len, 0);
        io_uring_sqe_set_data(sqe, userData);
    }
    
    // 비동기 송신 등록
    void prepareSend(int fd, const void* buffer, size_t len, void* userData) {
        io_uring_sqe* sqe = io_uring_get_sqe(&ring_);
        io_uring_prep_send(sqe, fd, buffer, len, 0);
        io_uring_sqe_set_data(sqe, userData);
    }
    
    // 배치 제출
    int submit() {
        return io_uring_submit(&ring_);
    }
    
    // 완료 이벤트 처리
    void processCompletions(std::function<void(void*, int)> handler) {
        io_uring_cqe* cqe;
        unsigned head;
        int count = 0;
        
        io_uring_for_each_cqe(&ring_, head, cqe) {
            void* userData = io_uring_cqe_get_data(cqe);
            handler(userData, cqe->res);
            count++;
        }
        
        io_uring_cq_advance(&ring_, count);
    }

private:
    io_uring ring_;
};

// 사용 예시: 고성능 UDP 서버
class HighPerfUDPServer {
public:
    void run() {
        // 수신 버퍼 사전 등록
        for (int i = 0; i < RECV_BUFFER_COUNT; i++) {
            network_.prepareRecv(socket_, buffers_[i], BUFFER_SIZE, &buffers_[i]);
        }
        network_.submit();
        
        while (running_) {
            network_.processCompletions([this](void* userData, int result) {
                if (result > 0) {
                    processPacket(userData, result);
                    // 버퍼 재사용
                    network_.prepareRecv(socket_, userData, BUFFER_SIZE, userData);
                }
            });
            network_.submit();
        }
    }
};
```

### Phase 3: 운영 성숙도 (Month 5-6)

#### 3.1 카오스 엔지니어링
```cpp
// ChaosEngine.hpp
class ChaosEngine {
public:
    // 장애 주입 유형
    enum class FaultType {
        NETWORK_LATENCY,    // 네트워크 지연 추가
        NETWORK_PARTITION,  // 네트워크 분할
        SERVER_CRASH,       // 서버 크래시
        CPU_STRESS,         // CPU 과부하
        MEMORY_PRESSURE,    // 메모리 압박
        DISK_FULL,          // 디스크 풀
    };

    struct FaultConfig {
        FaultType type;
        std::string target;         // 대상 서버/서비스
        Duration duration;          // 지속 시간
        float intensity = 1.0f;     // 강도 (0.0 ~ 1.0)
        std::string description;
    };

    // 장애 주입
    void injectFault(const FaultConfig& config);
    
    // 장애 해제
    void clearFault(const std::string& faultId);
    
    // 실험 실행
    struct ExperimentResult {
        bool passed;
        Duration recoveryTime;
        std::vector<std::string> observations;
        std::vector<std::string> recommendations;
    };
    
    ExperimentResult runExperiment(
        const std::string& hypothesis,
        const std::vector<FaultConfig>& faults,
        std::function<bool()> steadyStateCheck
    );
};

// 사용 예시: 리전 장애 복구 테스트
void testRegionFailover() {
    ChaosEngine chaos;
    
    auto result = chaos.runExperiment(
        "한국 리전 장애 시 일본 리전으로 자동 페일오버",
        {
            {FaultType::NETWORK_PARTITION, "region-kr", 5min, 1.0f, "한국 리전 격리"}
        },
        []() {
            // 정상 상태 확인: 모든 플레이어가 게임 가능
            return getAllPlayersCanPlay();
        }
    );
    
    EXPECT_TRUE(result.passed);
    EXPECT_LT(result.recoveryTime, 30s);  // 30초 이내 복구
}
```

#### 3.2 자동 스케일링
```cpp
// AutoScaler.hpp
class AutoScaler {
public:
    struct ScalingPolicy {
        std::string metricName;     // "cpu_usage", "player_count", "queue_depth"
        float scaleUpThreshold;
        float scaleDownThreshold;
        Duration cooldown;
        int minInstances;
        int maxInstances;
        int scaleUpStep;
        int scaleDownStep;
    };

    void setPolicy(const ScalingPolicy& policy) {
        policy_ = policy;
    }
    
    void evaluate() {
        float currentValue = getMetricValue(policy_.metricName);
        
        if (currentValue > policy_.scaleUpThreshold && canScale()) {
            scaleUp(policy_.scaleUpStep);
            lastScaleTime_ = now();
        } else if (currentValue < policy_.scaleDownThreshold && canScale()) {
            scaleDown(policy_.scaleDownStep);
            lastScaleTime_ = now();
        }
    }

private:
    bool canScale() {
        return (now() - lastScaleTime_) > policy_.cooldown;
    }
    
    void scaleUp(int count);
    void scaleDown(int count);
    
    ScalingPolicy policy_;
    TimePoint lastScaleTime_;
};

// 예측 기반 스케일링
class PredictiveScaler : public AutoScaler {
public:
    void evaluate() override {
        // 과거 데이터 기반 예측
        float predictedLoad = model_.predict(
            getHistoricalData(24h),
            forecastHorizon(1h)
        );
        
        // 예측 부하에 맞춰 미리 스케일
        int requiredInstances = calculateRequiredInstances(predictedLoad);
        scaleTo(requiredInstances);
    }

private:
    TimeSeriesModel model_;  // ARIMA, Prophet 등
};
```

#### 3.3 SLO/SLI 대시보드
```cpp
// SLOMonitor.hpp
class SLOMonitor {
public:
    struct SLI {
        std::string name;
        std::string query;  // Prometheus 쿼리
        float target;       // 목표값
        Duration window;    // 측정 윈도우
    };

    struct SLO {
        std::string name;
        std::vector<SLI> indicators;
        float targetAvailability;  // 예: 99.9%
        Duration budget;           // 에러 버짓 기간
    };

    // SLO 등록
    void registerSLO(const SLO& slo);
    
    // 현재 상태 조회
    struct SLOStatus {
        std::string sloName;
        float currentAvailability;
        Duration remainingBudget;
        bool isHealthy;
        std::vector<std::string> burningIndicators;
    };
    
    SLOStatus getStatus(const std::string& sloName);
    
    // 알림 설정
    void setAlert(
        const std::string& sloName,
        float budgetThreshold,      // 남은 버짓 비율
        std::function<void(const SLOStatus&)> alertHandler
    );
};

// 사용 예시
void setupGameServerSLOs() {
    SLOMonitor monitor;
    
    monitor.registerSLO({
        .name = "game-server-availability",
        .indicators = {
            {"latency_p99", "histogram_quantile(0.99, rate(request_latency_bucket[5m]))", 0.020, 5min},
            {"error_rate", "rate(errors_total[5m]) / rate(requests_total[5m])", 0.001, 5min},
            {"matchmaking_time", "histogram_quantile(0.95, rate(matchmaking_latency_bucket[5m]))", 30.0, 5min},
        },
        .targetAvailability = 0.999,  // 99.9%
        .budget = 30days
    });
    
    monitor.setAlert("game-server-availability", 0.5, [](const auto& status) {
        // 에러 버짓 50% 소진 시 알림
        sendSlackAlert("SLO budget burning: " + status.sloName);
    });
}
```

## 파일 구조

```
cpp-pvp-server/
├── server/
│   ├── src/
│   │   ├── global/                  # 새로 추가
│   │   │   ├── RegionCluster.cpp
│   │   │   ├── GlobalMatchmaking.cpp
│   │   │   └── CrossRegionSync.cpp
│   │   ├── performance/             # 새로 추가
│   │   │   ├── LockFreeQueue.hpp
│   │   │   ├── NUMAAllocator.cpp
│   │   │   └── IoUringNetwork.cpp
│   │   ├── operations/              # 새로 추가
│   │   │   ├── ChaosEngine.cpp
│   │   │   ├── AutoScaler.cpp
│   │   │   └── SLOMonitor.cpp
│   │   └── ...
│   └── tests/
│       ├── chaos/                   # 카오스 테스트
│       ├── load/                    # 부하 테스트
│       └── failover/                # 페일오버 테스트
├── infrastructure/                  # 새로 추가
│   ├── terraform/
│   │   ├── modules/
│   │   │   ├── region/
│   │   │   └── global/
│   │   └── environments/
│   │       ├── production/
│   │       └── staging/
│   └── kubernetes/
│       ├── base/
│       └── overlays/
└── design/
    └── v3.0.0-global-scale.md
```

## 기술적 제약사항

### 인프라 요구사항
- 최소 3개 리전 (한국, 일본, 싱가포르)
- 리전당 최소 3개 가용 영역
- 글로벌 로드밸런서 (Anycast)

### 성능 요구사항
- 리전 내 지연: < 20ms (p99)
- 크로스 리전 동기화: < 5초 (최종 일관성)
- 페일오버 시간: < 30초

### 운영 요구사항
- 99.9% 가용성 (연간 다운타임 < 8.76시간)
- RTO (Recovery Time Objective): 5분
- RPO (Recovery Point Objective): 1분

## 학습 자료

### 분산 시스템
- [Designing Data-Intensive Applications](https://dataintensive.net/)
- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)

### 성능 최적화
- [Systems Performance (Brendan Gregg)](https://www.brendangregg.com/systems-performance-2nd-edition-book.html)
- [The Art of Multiprocessor Programming](https://www.amazon.com/Art-Multiprocessor-Programming-Revised-Reprint/dp/0123973376)

### 카오스 엔지니어링
- [Chaos Engineering (O'Reilly)](https://www.oreilly.com/library/view/chaos-engineering/9781492043850/)
- [Netflix Chaos Monkey](https://netflix.github.io/chaosmonkey/)