# WebAudio 코어 엔진 설계 일지 (v3.2.0)
> Phase 3.2 시작 - WebAudio 기반 오디오 편집

## 1. 문제 정의 & 요구사항

### 1.1 핵심 목표

**v3.2.0 - WebAudio Core Engine**:
- **AudioContext 초기화**: 브라우저 오디오 시스템 설정
- **오디오 파일 로딩**: fetch + decodeAudioData
- **버퍼 관리**: AudioBuffer 풀링 및 재사용
- **디버깅**: 오디오 상태 추적

### 1.2 성능 요구사항

- 128 샘플 버퍼로 실시간 처리
- FFT 분석 < 10ms
- 메모리 사용 < 100MB

### 1.3 브라우저 지원

- Chrome 14+
- Firefox 25+
- Safari 6+
- Edge 12+

---

## 2. 아키텍처 설계

### 2.1 디렉토리 구조

```
frontend/src/audio/
├── WebAudioEngine.ts       # AudioContext 관리
├── AudioLoader.ts          # 파일 로딩
├── AudioBufferManager.ts   # 버퍼 풀링
├── AudioDebug.ts           # 디버깅 유틸리티
└── index.ts                # 모듈 익스포트
```

### 2.2 클래스 다이어그램

```
┌─────────────────────────────────────────────────────┐
│                  WebAudioEngine                      │
├─────────────────────────────────────────────────────┤
│ - context: AudioContext                             │
│ - masterGain: GainNode                              │
│ - loader: AudioLoader                               │
│ - bufferManager: AudioBufferManager                 │
├─────────────────────────────────────────────────────┤
│ + constructor()                                     │
│ + resume(): Promise<void>                           │
│ + suspend(): Promise<void>                          │
│ + getContext(): AudioContext                        │
│ + dispose(): void                                   │
└─────────────────────────────────────────────────────┘
         │
         ├──────────────────┬──────────────────┐
         ▼                  ▼                  ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│   AudioLoader   │ │AudioBufferMgr   │ │   AudioDebug    │
├─────────────────┤ ├─────────────────┤ ├─────────────────┤
│ + load()        │ │ + acquire()     │ │ + logState()    │
│ + decode()      │ │ + release()     │ │ + getMetrics()  │
│ + loadFromUrl() │ │ + getStats()    │ │ + visualize()   │
└─────────────────┘ └─────────────────┘ └─────────────────┘
```

---

## 3. 패치별 상세 설계

### 3.2.0.1: AudioContext 초기화

**파일**: `frontend/src/audio/WebAudioEngine.ts`

```typescript
interface AudioEngineOptions {
  sampleRate?: number;
  latencyHint?: AudioContextLatencyCategory;
}

class WebAudioEngine {
  private context: AudioContext;
  private masterGain: GainNode;
  private isResumed = false;
  
  constructor(options?: AudioEngineOptions) {
    this.context = new AudioContext({
      sampleRate: options?.sampleRate ?? 44100,
      latencyHint: options?.latencyHint ?? 'interactive',
    });
    
    this.masterGain = this.context.createGain();
    this.masterGain.connect(this.context.destination);
    
    // Auto-resume on user interaction
    this.setupAutoResume();
  }
  
  private setupAutoResume(): void {
    const resume = async () => {
      if (this.context.state === 'suspended') {
        await this.context.resume();
        this.isResumed = true;
      }
    };
    
    document.addEventListener('click', resume, { once: true });
    document.addEventListener('keydown', resume, { once: true });
  }
  
  async resume(): Promise<void> {
    if (this.context.state === 'suspended') {
      await this.context.resume();
    }
  }
  
  async suspend(): Promise<void> {
    if (this.context.state === 'running') {
      await this.context.suspend();
    }
  }
  
  getContext(): AudioContext {
    return this.context;
  }
  
  getMasterGain(): GainNode {
    return this.masterGain;
  }
  
  dispose(): void {
    this.context.close();
  }
}
```

**핵심 포인트**:
1. 자동 resume 설정 (브라우저 정책 대응)
2. 마스터 게인 노드로 전체 볼륨 제어
3. 리소스 정리 (dispose)

---

### 3.2.0.2: 오디오 파일 로딩

**파일**: `frontend/src/audio/AudioLoader.ts`

```typescript
interface LoadOptions {
  onProgress?: (progress: number) => void;
}

class AudioLoader {
  private context: AudioContext;
  private cache: Map<string, AudioBuffer> = new Map();
  
  constructor(context: AudioContext) {
    this.context = context;
  }
  
  async loadFromUrl(url: string, options?: LoadOptions): Promise<AudioBuffer> {
    // Check cache first
    if (this.cache.has(url)) {
      return this.cache.get(url)!;
    }
    
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`Failed to load audio: ${response.status}`);
    }
    
    const arrayBuffer = await response.arrayBuffer();
    const audioBuffer = await this.context.decodeAudioData(arrayBuffer);
    
    this.cache.set(url, audioBuffer);
    return audioBuffer;
  }
  
  async loadFromFile(file: File): Promise<AudioBuffer> {
    const arrayBuffer = await file.arrayBuffer();
    return this.context.decodeAudioData(arrayBuffer);
  }
  
  clearCache(): void {
    this.cache.clear();
  }
}
```

**핵심 포인트**:
1. URL 및 File 객체 지원
2. 캐싱으로 중복 로딩 방지
3. decodeAudioData로 디코딩

---

### 3.2.0.3: 오디오 버퍼 관리

**파일**: `frontend/src/audio/AudioBufferManager.ts`

```typescript
interface BufferStats {
  totalBuffers: number;
  pooledBuffers: number;
  activeBuffers: number;
  totalMemoryBytes: number;
}

class AudioBufferManager {
  private context: AudioContext;
  private pool: Map<string, AudioBuffer[]> = new Map();
  private active: Set<AudioBuffer> = new Set();
  
  private getKey(channels: number, length: number, sampleRate: number): string {
    return `${channels}_${length}_${sampleRate}`;
  }
  
  acquire(channels: number, length: number, sampleRate?: number): AudioBuffer {
    const rate = sampleRate ?? this.context.sampleRate;
    const key = this.getKey(channels, length, rate);
    
    const pooled = this.pool.get(key);
    if (pooled && pooled.length > 0) {
      const buffer = pooled.pop()!;
      this.active.add(buffer);
      return buffer;
    }
    
    const buffer = this.context.createBuffer(channels, length, rate);
    this.active.add(buffer);
    return buffer;
  }
  
  release(buffer: AudioBuffer): void {
    if (!this.active.has(buffer)) return;
    
    this.active.delete(buffer);
    const key = this.getKey(buffer.numberOfChannels, buffer.length, buffer.sampleRate);
    
    if (!this.pool.has(key)) {
      this.pool.set(key, []);
    }
    this.pool.get(key)!.push(buffer);
  }
  
  getStats(): BufferStats {
    let pooledCount = 0;
    this.pool.forEach(buffers => pooledCount += buffers.length);
    
    return {
      totalBuffers: this.active.size + pooledCount,
      pooledBuffers: pooledCount,
      activeBuffers: this.active.size,
      totalMemoryBytes: this.estimateMemory(),
    };
  }
  
  private estimateMemory(): number {
    let bytes = 0;
    this.active.forEach(buffer => {
      bytes += buffer.length * buffer.numberOfChannels * 4; // Float32
    });
    return bytes;
  }
}
```

---

### 3.2.0.4: WebAudio 디버깅

**파일**: `frontend/src/audio/AudioDebug.ts`

```typescript
interface AudioState {
  contextState: AudioContextState;
  sampleRate: number;
  currentTime: number;
  baseLatency: number;
  outputLatency: number;
}

class AudioDebug {
  private context: AudioContext;
  private enabled: boolean;
  
  constructor(context: AudioContext, enabled = true) {
    this.context = context;
    this.enabled = enabled && process.env.NODE_ENV === 'development';
  }
  
  getState(): AudioState {
    return {
      contextState: this.context.state,
      sampleRate: this.context.sampleRate,
      currentTime: this.context.currentTime,
      baseLatency: this.context.baseLatency,
      outputLatency: (this.context as any).outputLatency ?? 0,
    };
  }
  
  log(message: string, data?: any): void {
    if (!this.enabled) return;
    console.log(`[WebAudio] ${message}`, data ?? '');
  }
  
  logNodeGraph(rootNode: AudioNode): void {
    if (!this.enabled) return;
    console.log('[WebAudio] Node Graph:', this.serializeNodeGraph(rootNode));
  }
  
  private serializeNodeGraph(node: AudioNode): object {
    return {
      type: node.constructor.name,
      numberOfInputs: node.numberOfInputs,
      numberOfOutputs: node.numberOfOutputs,
      channelCount: node.channelCount,
    };
  }
}
```

---

## 4. 완료 기준

- [ ] AudioContext 초기화 및 resume
- [ ] 오디오 파일 로딩 및 디코딩
- [ ] 버퍼 재사용 시스템 동작
- [ ] 디버그 모드에서 상태 로깅

---

## 5. 다음 단계

→ v3.2.1: 오디오 노드 시스템
