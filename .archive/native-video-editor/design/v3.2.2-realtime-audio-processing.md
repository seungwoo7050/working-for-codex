# 실시간 오디오 프로세싱 설계 일지 (v3.2.2)
> Phase 3.2 - 고성능 오디오 처리

## 1. 문제 정의 & 요구사항

### 1.1 핵심 목표

**v3.2.2 - Real-time Audio Processing**:
- **ScriptProcessor**: 레거시 방식 오디오 처리
- **AudioWorklet**: 고성능 별도 스레드 처리
- **FFT 분석**: 주파수 도메인 분석
- **실시간 필터링**: 이퀄라이저 등

### 1.2 성능 목표

- 128 샘플 버퍼 지원
- 처리 지연 < 10ms
- 메인 스레드 블로킹 없음

---

## 2. 패치별 상세 설계

### 3.2.2.1: ScriptProcessor 노드

**파일**: `frontend/src/webaudio/ScriptProcessorWrapper.ts`

```typescript
type ProcessCallback = (
  inputBuffer: AudioBuffer,
  outputBuffer: AudioBuffer
) => void;

/**
 * @deprecated ScriptProcessorNode is deprecated, use AudioWorklet
 */
class ScriptProcessorWrapper {
  private processor: ScriptProcessorNode;
  private callback: ProcessCallback | null = null;
  
  constructor(
    context: AudioContext,
    bufferSize: number = 4096,
    inputChannels: number = 2,
    outputChannels: number = 2
  ) {
    this.processor = context.createScriptProcessor(
      bufferSize,
      inputChannels,
      outputChannels
    );
    this.processor.onaudioprocess = this.handleProcess.bind(this);
  }
  
  private handleProcess(event: AudioProcessingEvent): void {
    if (this.callback) {
      this.callback(event.inputBuffer, event.outputBuffer);
    } else {
      // Pass through
      for (let channel = 0; channel < event.outputBuffer.numberOfChannels; channel++) {
        const input = event.inputBuffer.getChannelData(channel);
        const output = event.outputBuffer.getChannelData(channel);
        output.set(input);
      }
    }
  }
  
  setCallback(callback: ProcessCallback): void {
    this.callback = callback;
  }
  
  getNode(): ScriptProcessorNode {
    return this.processor;
  }
  
  connect(destination: AudioNode): void {
    this.processor.connect(destination);
  }
  
  disconnect(): void {
    this.processor.disconnect();
  }
  
  getBufferSize(): number {
    return this.processor.bufferSize;
  }
  
  // 정적 팩토리 메서드들
  static createGainProcessor(context: AudioContext, gain: number = 1): ScriptProcessorWrapper;
  static createClipProcessor(context: AudioContext, threshold: number = 0.9): ScriptProcessorWrapper;
}
```

---

### 3.2.2.2: AudioWorklet 구현

**파일**: `frontend/src/webaudio/AudioWorkletManager.ts`

```typescript
interface WorkletProcessorInfo {
  name: string;
  loaded: boolean;
  moduleUrl: string;
}

class AudioWorkletManager {
  private context: AudioContext;
  private loadedProcessors: Map<string, WorkletProcessorInfo> = new Map();
  private isSupported: boolean;
  
  constructor(context: AudioContext) {
    this.context = context;
    this.isSupported = 'audioWorklet' in context;
  }
  
  checkSupport(): boolean {
    return this.isSupported;
  }
  
  async loadProcessor(name: string, moduleUrl: string): Promise<boolean> {
    if (!this.isSupported) {
      console.warn('AudioWorklet not supported');
      return false;
    }
    
    if (this.loadedProcessors.has(name)) return true;
    
    try {
      await this.context.audioWorklet.addModule(moduleUrl);
      this.loadedProcessors.set(name, { name, loaded: true, moduleUrl });
      return true;
    } catch (error) {
      console.error(`Failed to load AudioWorklet processor: ${name}`, error);
      return false;
    }
  }
  
  async loadProcessorFromCode(name: string, code: string): Promise<boolean> {
    if (!this.isSupported) return false;
    
    const blob = new Blob([code], { type: 'application/javascript' });
    const url = URL.createObjectURL(blob);
    
    try {
      const result = await this.loadProcessor(name, url);
      URL.revokeObjectURL(url);
      return result;
    } catch (error) {
      URL.revokeObjectURL(url);
      throw error;
    }
  }
  
  createNode(
    processorName: string,
    options?: AudioWorkletNodeOptions
  ): AudioWorkletNode | null {
    if (!this.isSupported) return null;
    if (!this.loadedProcessors.has(processorName)) {
      console.warn(`Processor "${processorName}" not loaded`);
      return null;
    }
    return new AudioWorkletNode(this.context, processorName, options);
  }
  
  isProcessorLoaded(name: string): boolean {
    return this.loadedProcessors.get(name)?.loaded ?? false;
  }
  
  getLoadedProcessors(): string[] {
    return Array.from(this.loadedProcessors.keys());
  }
  
  static getGainProcessorCode(): string {
    return `
      class GainProcessor extends AudioWorkletProcessor {
        static get parameterDescriptors() {
          return [{
            name: 'gain',
            defaultValue: 1,
            minValue: 0,
            maxValue: 2,
            automationRate: 'k-rate'
          }];
        }
        process(inputs, outputs, parameters) {
          const input = inputs[0];
          const output = outputs[0];
          const gain = parameters.gain;
          for (let ch = 0; ch < input.length; ch++) {
            for (let i = 0; i < input[ch].length; i++) {
              output[ch][i] = input[ch][i] * (gain.length > 1 ? gain[i] : gain[0]);
            }
          }
          return true;
        }
      }
      registerProcessor('gain-processor', GainProcessor);
    `;
  }
}
```

---

### 3.2.2.3: FFT 분석

**파일**: `frontend/src/webaudio/FFTAnalyzer.ts`

```typescript
interface FFTData {
  frequencyData: Uint8Array;    // 주파수별 진폭 (0-255)
  timeDomainData: Uint8Array;   // 시간 영역 파형 (0-255)
  frequencies: Float32Array;    // 각 빈의 실제 주파수 (Hz)
}

interface FrequencyBands {
  sub: number;      // 20-60 Hz (서브베이스)
  bass: number;     // 60-250 Hz (베이스)
  lowMid: number;   // 250-500 Hz (저중음)
  mid: number;      // 500-2000 Hz (중음, 보컬 핵심)
  highMid: number;  // 2000-4000 Hz (고중음)
  high: number;     // 4000-20000 Hz (고음)
}

class FFTAnalyzer {
  private context: AudioContext;
  private analyser: AnalyserNode;
  private frequencyData: Uint8Array;
  private timeDomainData: Uint8Array;
  private floatFrequencyData: Float32Array;
  
  constructor(
    context: AudioContext,
    fftSize: number = 2048,
    smoothingTimeConstant: number = 0.8
  ) {
    this.context = context;
    this.analyser = context.createAnalyser();
    this.analyser.fftSize = fftSize;
    this.analyser.smoothingTimeConstant = smoothingTimeConstant;
    
    const bufferLength = this.analyser.frequencyBinCount;
    this.frequencyData = new Uint8Array(bufferLength);
    this.timeDomainData = new Uint8Array(bufferLength);
    this.floatFrequencyData = new Float32Array(bufferLength);
  }
  
  getNode(): AnalyserNode {
    return this.analyser;
  }
  
  setFFTSize(size: number): void {
    this.analyser.fftSize = size;
    const bufferLength = this.analyser.frequencyBinCount;
    this.frequencyData = new Uint8Array(bufferLength);
    this.timeDomainData = new Uint8Array(bufferLength);
    this.floatFrequencyData = new Float32Array(bufferLength);
  }
  
  setSmoothing(value: number): void {
    this.analyser.smoothingTimeConstant = Math.max(0, Math.min(1, value));
  }
  
  getFrequencyData(): Uint8Array {
    this.analyser.getByteFrequencyData(this.frequencyData);
    return this.frequencyData;
  }
  
  getFloatFrequencyData(): Float32Array {
    this.analyser.getFloatFrequencyData(this.floatFrequencyData);
    return this.floatFrequencyData;
  }
  
  getTimeDomainData(): Uint8Array {
    this.analyser.getByteTimeDomainData(this.timeDomainData);
    return this.timeDomainData;
  }
  
  getFrequencyBinCount(): number {
    return this.analyser.frequencyBinCount;
  }
  
  binToFrequency(bin: number): number {
    return bin * this.context.sampleRate / this.analyser.fftSize;
  }
  
  frequencyToBin(frequency: number): number {
    return Math.round(frequency * this.analyser.fftSize / this.context.sampleRate);
  }
}
```

---

### 3.2.2.4: 실시간 필터링

**파일**: `frontend/src/webaudio/AudioFilters.ts`

```typescript
type FilterPreset = 
  | 'lowpass' 
  | 'highpass' 
  | 'bandpass' 
  | 'notch' 
  | 'lowshelf' 
  | 'highshelf' 
  | 'peaking'
  | 'allpass';

interface FilterConfig {
  type: BiquadFilterType;
  frequency: number;
  Q?: number;
  gain?: number;
}

interface EQBand {
  filter: BiquadFilterNode;
  frequency: number;
  gain: number;
}

class AudioFilters {
  private context: AudioContext;
  
  constructor(context: AudioContext) {
    this.context = context;
  }
  
  createFilter(config: FilterConfig): BiquadFilterNode {
    const filter = this.context.createBiquadFilter();
    filter.type = config.type;
    filter.frequency.value = config.frequency;
    if (config.Q !== undefined) filter.Q.value = config.Q;
    if (config.gain !== undefined) filter.gain.value = config.gain;
    return filter;
  }
  
  createLowpass(frequency: number, Q: number = 1): BiquadFilterNode {
    return this.createFilter({ type: 'lowpass', frequency, Q });
  }
  
  createHighpass(frequency: number, Q: number = 1): BiquadFilterNode {
    return this.createFilter({ type: 'highpass', frequency, Q });
  }
  
  createBandpass(frequency: number, Q: number = 1): BiquadFilterNode {
    return this.createFilter({ type: 'bandpass', frequency, Q });
  }
  
  createNotch(frequency: number, Q: number = 10): BiquadFilterNode {
    return this.createFilter({ type: 'notch', frequency, Q });
  }
  
  createLowShelf(frequency: number, gain: number): BiquadFilterNode {
    return this.createFilter({ type: 'lowshelf', frequency, gain });
  }
  
  createHighShelf(frequency: number, gain: number): BiquadFilterNode {
    return this.createFilter({ type: 'highshelf', frequency, gain });
  }
  
  createPeaking(frequency: number, Q: number, gain: number): BiquadFilterNode {
    return this.createFilter({ type: 'peaking', frequency, Q, gain });
  }
}
```

---

## 3. 완료 기준

- [ ] ScriptProcessor 기본 동작
- [ ] AudioWorklet 고성능 처리
- [ ] FFT 분석 < 10ms
- [ ] 실시간 필터 적용

---

## 4. 다음 단계

→ v3.2.3: 오디오 시각화
